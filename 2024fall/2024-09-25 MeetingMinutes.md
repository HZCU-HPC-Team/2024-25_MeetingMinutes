# 2024-09-25 HZCU-HPCT 第二次例会

## 大一 入门

git [git入门教程 · GitBook (nju-projectn.github.io)](https://nju-projectn.github.io/ics-pa-gitbook/ics2022/git.html)

git game [Learn Git Branching](https://learngitbranching.js.org/?locale=zh_CN)

IDE 选择 vscode ssh remote, c extension... extensions ...

Tutorial: csdn 知乎 博客园  Stackoverflow ... AI Toolkit 使用, Coding assist

梯子 网络代理？ Zhuhan Bao + Shenyi Wang 帮助一下。

了解  **SSH Git**  这两个事情 

### Asst 1

配置一个本机能够跑C语言程序的 vscode 环境

IDE 选择 vscode extensions.

### Asst 2

注册一个github账户并登录。

使用 vscode ssh remote extension 连接 HPCT_Server IP: 10.61.190.8，具体的账号密码会私发给各位。


### Asst 3 (extra)

完成1BRC挑战

1BRC: [HZCU-HPCT/24fall_1brc: The One Billion Row Challenge using C++ (github.com)](https://github.com/HZCU-HPCT/24fall_1brc)

使用上面所提到的若干内容，理解挑战内容，并进行代码优化。

## 大二 CMU 15.418 

### PRA24

赛题进展，以及下一步推进

[1. Slurm简介 — Slurm资源管理与作业调度系统安装配置 2021-12 文档 (ustc.edu.cn)](http://hmli.ustc.edu.cn/doc/linux/slurm-install/slurm-install.html)

Basic Api: [3.2 HIP核函数 · DCU 开发与使用文档 (hpccube.com)](https://developer.hpccube.com/gitbook//dcu_developer/DeveloperGuide/dcu_programming/DCU_programming_chapter3_2.html)

Profiling [3.7 HIP 性能分析 · DCU 开发与使用文档 (hpccube.com)](https://developer.hpccube.com/gitbook//dcu_developer/DeveloperGuide/dcu_programming/DCU_programming_chapter3_7.html#372-hiptx-trace%E5%8A%9F%E8%83%BD)

Example: [3.10 DCU程序优化方法 · DCU 开发与使用文档 (hpccube.com)](https://developer.hpccube.com/gitbook//dcu_developer/DeveloperGuide/dcu_programming/DCU_programming_chapter3_10.html)


pra 赛题分工：

Prefetch: Nuo Xu

访存优化: Zhuhan Bao

算法类优化修改: Zhen Cai

硬件资源dcu 了解: Jiawei Lin

### 科研汇报时间  Wed 10 AM

1. 大致浏览 ZJU ARCLAB 发表的相关论文。
2. 至少选择一篇比较感兴趣的文献并进行精读, 精读前私发给我具体文章。

### Asst 1

Website: [15-418/15-618: Parallel Computer Architecture and Programming, Spring 2024 (cmu.edu)](https://www.cs.cmu.edu/~418)

[cmu15418f24/asst1 (github.com)](https://github.com/cmu15418f24/asst1)

两周时间完成

## 大三 AI Inference ASC 25 Preliminary

Base Model: Qwen 2.5 7B [Qwen2.5: 基础模型大派对！ | Qwen (qwenlm.github.io)](https://qwenlm.github.io/zh/blog/qwen2.5/#:~:text=Qwen2.5%20%E6%A8%A1%E5%9E%8B) 

AI Framework: Hugging Face Transformer | vLLM 后端推理加速框架

Qwen2 technical report[[2407.10671 (arxiv.org)](https://arxiv.org/pdf/2407.10671)]

Efficient Large Language Model: A Survey: [2312.03863 (arxiv.org)](https://arxiv.org/pdf/2312.03863)

### Report

两周后做技术报告解读 + 推理相关的内容报告

RQ1 Qwen2.5 训练过程中用到了什么加速技术: Nuo Xu

RQ2 vLLM 如何加速当前的LLM推理: Nuo Xu

RQ3 能否在vLLM 框架 用一些其他的加速技术: Chendong shen

RQ4 QWen 2.5 7B 跑起来+ 环境配置: Shenyi Wang 

RQ5 vLLM QWen benchmark infer speed. 你是怎么衡量速度的: Shenyi Wang

RQ6 Hugging Face Transformer 加速比是什么 用一些其他的加速技术 他们有什么其他的加速比:  Chendong Shen

## *下一次例会时间 2024 10 09 18:00 理四 508*
